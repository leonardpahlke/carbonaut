[{"id":0,"href":"/docs/","title":"Example Site","section":"Introduction","content":" Introduction # Ferre hinnitibus erat accipitrem dixi Troiae tollens # Lorem markdownum, a quoque nutu est quodcumque mandasset veluti. Passim inportuna totidemque nympha fert; repetens pendent, poenarum guttura sed vacet non, mortali undas. Omnis pharetramque gramen portentificisque membris servatum novabis fallit de nubibus atque silvas mihi. Dixit repetitaque Quid; verrit longa; sententia mandat quascumque nescio solebat litore; noctes. Hostem haerentem circuit plenaque tamen.\nPedum ne indigenae finire invergens carpebat Velit posses summoque De fumos illa foret Est simul fameque tauri qua ad # Locum nullus nisi vomentes. Ab Persea sermone vela, miratur aratro; eandem Argolicas gener.\nMe sol # Nec dis certa fuit socer, Nonacria dies manet tacitaque sibi? Sucis est iactata Castrumque iudex, et iactato quoque terraeque es tandem et maternos vittis. Lumina litus bene poenamque animos callem ne tuas in leones illam dea cadunt genus, et pleno nunc in quod. Anumque crescentesque sanguinis progenies nuribus rustica tinguet. Pater omnes liquido creditis noctem.\nif (mirrored(icmp_dvd_pim, 3, smbMirroredHard) != lion(clickImportQueue, viralItunesBalancing, bankruptcy_file_pptp)) { file += ip_cybercrime_suffix; } if (runtimeSmartRom == netMarketingWord) { virusBalancingWin *= scriptPromptBespoke + raster(post_drive, windowsSli); cd = address_hertz_trojan; soap_ccd.pcbServerGigahertz(asp_hardware_isa, offlinePeopleware, nui); } else { megabyte.api = modem_flowchart - web + syntaxHalftoneAddress; } if (3 \u0026lt; mebibyteNetworkAnimated) { pharming_regular_error *= jsp_ribbon + algorithm * recycleMediaKindle( dvrSyntax, cdma); adf_sla *= hoverCropDrive; templateNtfs = -1 - vertical; } else { expressionCompressionVariable.bootMulti = white_eup_javascript( table_suffix); guidPpiPram.tracerouteLinux += rtfTerabyteQuicktime(1, managementRosetta(webcamActivex), 740874); } var virusTweetSsl = nullGigo; Trepident sitimque # Sentiet et ferali errorem fessam, coercet superbus, Ascaniumque in pennis mediis; dolor? Vidit imi Aeacon perfida propositos adde, tua Somni Fluctibus errante lustrat non.\nTamen inde, vos videt e flammis Scythica parantem rupisque pectora umbras. Haec ficta canistris repercusso simul ego aris Dixit! Esse Fama trepidare hunc crescendo vigor ululasse vertice exspatiantur celer tepidique petita aversata oculis iussa est me ferro.\n"},{"id":1,"href":"/docs/table-of-contents/with-toc/","title":"With ToC","section":"Table of Contents","content":" Caput vino delphine in tamen vias # Cognita laeva illo fracta # Lorem markdownum pavent auras, surgit nunc cingentibus libet Laomedonque que est. Pastor An arbor filia foedat, ne fugit aliter, per. Helicona illas et callida neptem est Oresitrophos caput, dentibus est venit. Tenet reddite famuli praesentem fortibus, quaeque vis foret si frondes gelidos gravidae circumtulit inpulit armenta nativum.\nTe at cruciabere vides rubentis manebo Maturuit in praetemptat ruborem ignara postquam habitasse Subitarum supplevit quoque fontesque venabula spretis modo Montis tot est mali quasque gravis Quinquennem domus arsit ipse Pellem turis pugnabant locavit Natus quaerere # Pectora et sine mulcere, coniuge dum tincta incurvae. Quis iam; est dextra Peneosque, metuis a verba, primo. Illa sed colloque suis: magno: gramen, aera excutiunt concipit.\nPhrygiae petendo suisque extimuit, super, pars quod audet! Turba negarem. Fuerat attonitus; et dextra retinet sidera ulnas undas instimulat vacuae generis? Agnus dabat et ignotis dextera, sic tibi pacis feriente at mora euhoeque comites hostem vestras Phineus. Vultuque sanguine dominoque metuit risi fama vergit summaque meus clarissimus artesque tinguebat successor nominis cervice caelicolae.\nLimitibus misere sit # Aurea non fata repertis praerupit feruntur simul, meae hosti lentaque citius levibus, cum sede dixit, Phaethon texta. Albentibus summos multifidasque iungitur loquendi an pectore, mihi ursaque omnia adfata, aeno parvumque in animi perlucentes. Epytus agis ait vixque clamat ornum adversam spondet, quid sceptra ipsum est. Reseret nec; saeva suo passu debentia linguam terga et aures et cervix de ubera. Coercet gelidumque manus, doluit volvitur induta?\nEnim sua # Iuvenilior filia inlustre templa quidem herbis permittat trahens huic. In cruribus proceres sole crescitque fata, quos quos; merui maris se non tamen in, mea.\nGermana aves pignus tecta # Mortalia rudibusque caelum cognosceret tantum aquis redito felicior texit, nec, aris parvo acre. Me parum contulerant multi tenentem, gratissime suis; vultum tu occupat deficeret corpora, sonum. E Actaea inplevit Phinea concepit nomenque potest sanguine captam nulla et, in duxisses campis non; mercede. Dicere cur Leucothoen obitum?\nPostibus mittam est nubibus principium pluma, exsecratur facta et. Iunge Mnemonidas pallamque pars; vere restitit alis flumina quae quoque, est ignara infestus Pyrrha. Di ducis terris maculatum At sede praemia manes nullaque!\n"},{"id":2,"href":"/docs/table-of-contents/","title":"Table of Contents","section":"Example Site","content":" Ubi loqui # Mentem genus facietque salire tempus bracchia # Lorem markdownum partu paterno Achillem. Habent amne generosi aderant ad pellem nec erat sustinet merces columque haec et, dixit minus nutrit accipiam subibis subdidit. Temeraria servatum agros qui sed fulva facta. Primum ultima, dedit, suo quisque linguae medentes fixo: tum petis.\nRapit vocant si hunc siste adspice # Ora precari Patraeque Neptunia, dixit Danae Cithaeron armaque maxima in nati Coniugis templis fluidove. Effugit usus nec ingreditur agmen ac manus conlato. Nullis vagis nequiquam vultibus aliquos altera suum venis teneas fretum. Armos remotis hoc sine ferrea iuncta quam!\nLocus fuit caecis # Nefas discordemque domino montes numen tum humili nexilibusque exit, Iove. Quae miror esse, scelerisque Melaneus viribus. Miseri laurus. Hoc est proposita me ante aliquid, aura inponere candidioribus quidque accendit bella, sumpta. Intravit quam erat figentem hunc, motus de fontes parvo tempestate.\niscsi_virus = pitch(json_in_on(eupViral), northbridge_services_troubleshooting, personal( firmware_rw.trash_rw_crm.device(interactive_gopher_personal, software, -1), megabit, ergonomicsSoftware(cmyk_usb_panel, mips_whitelist_duplex, cpa))); if (5) { managementNetwork += dma - boolean; kilohertz_token = 2; honeypot_affiliate_ergonomics = fiber; } mouseNorthbridge = byte(nybble_xmp_modem.horse_subnet( analogThroughputService * graphicPoint, drop(daw_bit, dnsIntranet), gateway_ospf), repository.domain_key.mouse(serverData(fileNetwork, trim_duplex_file), cellTapeDirect, token_tooltip_mashup( ripcordingMashup))); module_it = honeypot_driver(client_cold_dvr(593902, ripping_frequency) + coreLog.joystick(componentUdpLink), windows_expansion_touchscreen); bashGigabit.external.reality(2, server_hardware_codec.flops.ebookSampling( ciscNavigationBacklink, table + cleanDriver), indexProtocolIsp); Placabilis coactis nega ingemuit ignoscat nimia non # Frontis turba. Oculi gravis est Delphice; inque praedaque sanguine manu non.\nif (ad_api) { zif += usb.tiffAvatarRate(subnet, digital_rt) + exploitDrive; gigaflops(2 - bluetooth, edi_asp_memory.gopher(queryCursor, laptop), panel_point_firmware); spyware_bash.statePopApplet = express_netbios_digital( insertion_troubleshooting.brouter(recordFolderUs), 65); } recursionCoreRay = -5; if (hub == non) { portBoxVirus = soundWeb(recursive_card(rwTechnologyLeopard), font_radcab, guidCmsScalable + reciprocalMatrixPim); left.bug = screenshot; } else { tooltipOpacity = raw_process_permalink(webcamFontUser, -1); executable_router += tape; } if (tft) { bandwidthWeb *= social_page; } else { regular += 611883; thumbnail /= system_lag_keyboard; } Caesorum illa tu sentit micat vestes papyriferi # Inde aderam facti; Theseus vis de tauri illa peream. Oculos uberaque non regisque vobis cursuque, opus venit quam vulnera. Et maiora necemque, lege modo; gestanda nitidi, vero? Dum ne pectoraque testantur.\nVenasque repulsa Samos qui, exspectatum eram animosque hinc, aut manes, Assyrii. Cupiens auctoribus pariter rubet, profana magni super nocens. Vos ius sibilat inpar turba visae iusto! Sedes ante dum superest extrema.\n"},{"id":3,"href":"/docs/concepts/architecture/","title":"Architecture","section":"Concepts","content":"To get an overview of the resource consumption of a cloud native system, you need to combine different data sources with each other. Carbonaut should be the platform to facilitate the data integration and transformation. To explore the architecture of the carbonaut system we first start with the data sources.\nData Sources # These data sources can be integrated dynamically (we add a data stream to the system) or static as (we use a configuration file to select a formular).\nDynamic Data Sources:\nEnergy: Energy metrics that gives us information about joules used which can be mapped to KwH. IT Resources: IT Resources that include various hardware information like CPU type, CPU cores, storage, DRAM etc. Geolocation: geolocation (longitude, latitude) based on IP address Energy Mix: current energy mix for the specified geolocation Static Data Sources:\nEmission: formualar to estimate the emissions based on the energy consumption, energy mix and IT resource typ. These data sources depend on each other.\ngraph TD; GEOLOCATION[Geolocation] --depends on--\u003e IT_RESOURCE[IT Resource]; ENERGY_MIX[Energy Mix] --depends on--\u003e GEOLOCATION; ENERGY[Energy] --depends on--\u003e IT_RESOURCE; EMISSION[Emission] --depends on--\u003e ENERGY; EMISSION --depends on--\u003e ENERGY_MIX; EMISSION --depends on--\u003e IT_RESOURCE; From this diagram its clear that in order to expose data about the emissions of the system, it is required to first collect all the other data sources of the system.\nEach of these types of data\nArchitecture Overview # Version 1.0 April 2024\nThis document describes the architecture of the Carbonaut project. Iterations on the architecture as well as deep dives into certain parts are written up in dedicated files.\n1. Overview # This documentation follows the Google Software Design Document structure.\n1.1. Purpose # Carbonaut is used to collect, integrate, and publish metrics related to the sustainability of cloud native environments. It seamlessly integrates with the observability stack in a cloud native setting.\nEnvironmental considerations and awareness of resource usage are generally emerging fields in economics, compelling us to discover innovative approaches for our products and services. For instance, we are transitioning from fast fashion to sustainable fashion, from coal to renewables, and from gasoline-powered to electric and hydrogen vehicles. This requires building an understanding of the supply chain and taking responsibility for how your products or services are assembled. These sustainable transformations vary in impact and quality but affect everything, including software engineering. Software represents another transformation in our economies, challenging current business models in various aspects. Sustainable software engineering merges these transformations.\nIn the realm of software, we find areas like distributed systems and cloud computing, which are major consumers of energy. It is estimated that the energy consumed by data centers globally emits more greenhouse gases than the aviation industry. Therefore, there is a pressing need to engage in this transformation and shape cloud technology in a more sustainable manner. Fortunately, this field is not confined to private companies but is a significant and industry-relevant area known as cloud native.\n1.2. Scope # This project focuses on the development of a single module that may be extended through plugins. If developed plugins should be integrated directly into the module, resulting in a single binary. There may also be an option to deploy multiple instances of this module to support higher throughput.\nThe primary role of the module is not to collect metrics itself; rather, it integrates with other tools that generate these metrics. However, to enhance the quality of the metrics by combining and refining them, such functionality can be incorporated within the module.\n1.3. Requirements # 1.3.1. Functional Requirements**: # Plugin Integration and Management: The system must support the integration of plugins directly into the main module, creating a unified binary. The module must provide an interface for loading and managing plugins. All plugins will follow a common integration structure which has to be defined. The \u0026ldquo;kinds\u0026rdquo; of a plugin is defined by the data required by the system. One data type, one plugin. Data Collection and Integration: While the module itself will not collect metrics directly, it must integrate seamlessly with external interfaces and tools that provide these metrics. The system must normalize data from various sources to a common schema suitable for analysis and reporting. The exposed metrics should be in opentelemetry format. Metric Enhancement: The module should have the capability to enhance the quality of metrics by combining data from multiple sources if reasonable. For example, in order to estimate carbon emissions energy, it resource and energy data needs to be caluclated. Scalability and Deployment: The system should support deployment in both single and multiple module configurations to facilitate varying levels of throughput. Ensure that the system can scale horizontally to manage increased load by adding more instances as required. Data Privacy and Security: Implement standard security measures to protect data integrity and confidentiality during the data collection and integration processes. Compliance with relevant data protection regulations must be ensured. 1.3.2. Non-Functional Requirements: # Performance: The system must process data efficiently, ensuring minimal latency in metric availability. Performance benchmarks should be established, particularly for data processing speeds and response times \u0026lt;100 milliseconds and in bulk \u0026lt;5 second. Reliability: The system must be robust, with capabilities to handle failures gracefully and ensure continuous operation. In the event that a module fails any modules that depend on it will either stop execution or publish parts of the requested data if available for later analysis. The user should have an interface to be aware of any failures happening. Upcon recovery modules should automatically restart, seaminglessly integrating already collected data if present with new data. Usability: The interface for managing plugins and configurations must be user-friendly, catering to technical users. Logs generated through using the system can be either send to the terminal or written in a file for further analysis. The system provides documentation on system setup, configuration, and management. Maintainability: The code base should be documented on a separate website and structured in such a way that easy maintenance and future upgrades are possible. The code follows common standards in terms of lining, inline comments and unit, integration and other testing if appropiate. In this way, it adheres to coding standards that promote code readability and reusability. Interoperability: The module should be compatible with existing and commonly used cloud native tools and platforms. Support for open standards and protocols to ensure seamless integration with a variety of data sources and tools. Open Source Development: The project is developed as open source project from the start. This includes a public repository, documentation, feature management, development and community structures (if required). 2. System Architecture # 2.1. Context # Carbonaut fits in a cloud native system.\nsequenceDiagram Alice-\u003e\u003eJohn: Hello John, how are you? John--\u003e\u003eAlice: Great! Alice-)John: See you later! 2.2. Plugins # 2.3. Internal Components / Building Blocks # 2.4. Deployment # 3. Data Dictionary # 4. Software Domain Design # 4.1. Software Application Domain Chart # 4.2. Software Application Domain # 4.2.1. Domain X # 4.2.1.1. Component Y of Domain X # 4.2.1.1. Task Z of Component Y1 of Domain X # 5. Data Design # Since the module does not store the data itself but rather exposes it, no additional database is required.\nscalability and performance\nsecurity considerations related to data\n5.1. Persistent/Static Data # 5.1.1. Dataset # 5.1.1. Static Data # 5.1.1. Persisted data # There is none persistent data. There may be data stored at runtime based on failures of plugins within the module which can force another plugin to \u0026ldquo;hold on the data\u0026rdquo; until the other plugin was restarted, the application shut down or no memory is left.\n5.2. Transient/Dynamic Data # This is the main part of the application.\n5.3. External Interface Data # 5.4. Transformation of Data # 6. User Interface # 6.1. User Interface Design Overview # 6.2. User Interface Navigation Flow # 6.3. Use Cases / User Function Description # 7. External Interfaces # 7.1. Interface X # 8. Comments # 9. References # 10. Glossary # "},{"id":4,"href":"/docs/concepts/architecture_old/","title":"Architecture Old","section":"Concepts","content":"This page describes the architecture of the Carbonaut project. This document is intended to convey the essence of the architecture, with further details available on separate concept sub-pages. The diagram below shows the general overview of the Carbonaut project, by describing each individual components in the following sections.\nContext # The Carbonaut project aims to establish a data layer for environmental sustainability related software data so that it can be used by a variety of applications. More information about the vision and goals are found here â†’. The diagram below shows the general context of Carbonaut.\n\u0026hellip;\nTo set up a data layer, Carbonaut needs to collect data from various sources and integrate it into a common schema that can be used by applications. To know how your IT infrastructure is designed, you need to know about your deployments in Kubernetes or in cloud. To calculate the carbon footprint of your applications, you also need to know about the energy consumption of the data centers you use. All of this needs to be integrated, and since the data comes from multiple sources, it needs to be normalized. Especially for large companies with many different applications, this is a complex task.\nBig Data Setting # In general, the project is placed in a big data system setting. As mentioned before, establish a software sustainability data layer, the project needs to work with loads of different kinds of heterogeneous data formats and needs to integrate the data into a common schema. If we follow a generic big data architecture, we have something like the diagram shown below.\n\u0026hellip;\nThe ETL service is responsible for performing the data integration of the different kinds of data sources. The ETL sends the data through a data stream (e.g., Apache Spark) and into a database. Another service does analytics on the stored data, for example in real time through the data stream or via batching on top of the database. An API provides a nice interface of the collected data to display it in a user interface. Carbonaut could follow this pattern and build an entire end to end suite.\nHowever, usually, there is no need to build an entire system and the Carbonaut idea can be embedded in existing systems. The Cloud Native community build powerful standards and tools with Prometheus and Open Telemetry, which can be extended. The Carbonaut project therefore proposes single building blocks which can be integrated in your big data system without dictating the entire end to end big data system. The diagram below illustrates this idea.\n\u0026hellip;\nReflecting on the big data architecture diagram further, the main core components, which are Carbonaut specific, are the ETL service and to some extent the analytics service. All the other components can be defined by the end user and are not core to the Carbonaut project. The Carbonaut project implements this ETL service, which also performs lightweight static analysis.\nCarbonaut Building Blocks # The technical components of Carbonaut are shown below.\n\u0026hellip;\nComponents:\nCore: The core puts all the other components together. It is responsible for the lifecycle management. Configuration Management: Carbonaut uses yaml files for its configuration. Updating the configuration results in a restart of Carbonaut. Connector: The connector is responsible for loading and managing plugins. Plugins can be deployed as subprocess inside the Carbonaut container or managed independently as a seperate process. Regardless of the deployment, plugins implement a gRPC server which is used to communicate with the plugin adapter. Data Mixer: The data mixer joins by configuration data sources from different metrics together to create higher quality metrics (for example, emissions for your Kubernetes nodes based on the energy consumption and location of the underlying data center). The data mixer should allow to swap out data models and caluclations at runtime without altering the origin of the data. Analyzer: The analyzer is responsible for performing static analysis on the data. The analyzer is also responsible for creating meta-metrics about the data collection. Metrics Server: The metrics server exposes the metrics in the Open Telemetry format. Plugin A and Plugin B are two different plugins shown to illustrate the Connector component. The Connector integrates with any number of plugins that implement the gRPC client.\nData flow # Carbonaut data integration is split into three sections, which are executed after one another.\nFirst, the plugins gather raw data from the data sources. This data is vendor-specific and can be in any format. The plugins are responsible for normalizing the data into a common format. The common format is the Carbonaut DTO schemas (DTO stands for Data Transfer Object). The connector receives the normalized data from the plugins and sends it to the analytics component, which includes the data mixer subcomponent, the meta metrics subcomponent and the DTO transformer subcomponent. The data mixer joins the data from different plugins together and creates MixedMetrics. The meta metrics subcomponent creates meta metrics about the data collection. The DTO transformer subcomponent transforms the data DTO schemas into Carbonaut metrics without performing further data manipulation. The metrics server requests the metrics data schemas from the analytics component and exposes them in the Open Telemetry format. The following diagram shows the data flow with four plugins connected as an example.\n\u0026hellip;\nThe page Carbonaut Data Schema describes the data schemas in more detail and the page Carbonaut Data Mixer describes how the data mixer enriches different data sources.\nDeployment # Carbonaut can be deployed in two flavours, single deployment mode (e.g. one container) or multi deployment mode (e.g. multiple containers). The fist diagram shows the single container mode where plugings are started as subprocesses and integrated via gRPC. The second diagram shows the multi container mode where plugins are run as seperate instances (for example as containers) which are also integrated via gRPC.\n\u0026hellip;\nSingle Deployment Guide \u0026hellip;\nMulti Deployment Guide \u0026hellip;\nFor some big systems a single Carbonaut depolyment will be the bottleneck. In this case it is possible to run multiple Carbonaut instances in parallel with a distinct plugin configuration.\n"},{"id":5,"href":"/docs/concepts/connector-pugins/","title":"Connector Pugins","section":"Concepts","content":" Connector Plugins # \u0026hellip;\n"},{"id":6,"href":"/docs/concepts/data-mixer/","title":"Data Mixer","section":"Concepts","content":" Data Mixer # \u0026hellip;\n"},{"id":7,"href":"/docs/concepts/data-schema/","title":"Data Schema","section":"Concepts","content":" Data Schema # \u0026hellip;\n"}]